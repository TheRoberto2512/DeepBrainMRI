{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Cr2sP8kznPr4",
        "fNUJz9e7ZTXf",
        "g2AXM-YIcNba",
        "bO-rCha5dosP",
        "cR6jfBdtsK8z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRoberto2512/DeepBrainMRI/blob/main/Pre%20Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm6QztNwNgEI"
      },
      "source": [
        "<font size=6>**FACE MORPHING DETECTION: PRE-PROCESSING**</font>\n",
        "</br><font size=3>*Roberto A. Usai, Davide Senette, Chiara Scalas*</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sapy5CCaXhTE"
      },
      "source": [
        "<p align=\"justify\">In questo notebook si può gestire il ridimensionamento delle immagini e il bilanciamento del dataset adottando un approccio misto tra data augmentation e random undersampling. Le funzioni sono parametrizzate, pertanto è possibile scegliere quante immagini generare con la data augmentation e quante eliminarle tramite random undersampling.\n",
        "<br><br>\n",
        "Infine, è possibile comprimere il dataset appena bilanciato e scaricarlo in formato .zip, in modo da poterlo utilizzare facilmente con gli altri notebook del progetto.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3kI7IGXgUO"
      },
      "source": [
        "**Indice:**\n",
        "*   [Import librerie e impostazioni](#1)\n",
        "*   [Download del Dataset](#2)\n",
        "*   [Resize delle immagini](#3)\n",
        "*   [Bilanciamento](#4)\n",
        "*   [Salvataggio](#5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr2sP8kznPr4"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "# **Import librerie e impostazioni**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-resize-image # libreria per fare il resize delle immagini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws02HhLXMpGQ",
        "outputId": "3731b172-d972-458c-bc0a-76a99bc6badc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-resize-image\n",
            "  Downloading python_resize_image-1.1.20-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from python-resize-image) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.19.1 in /usr/local/lib/python3.10/dist-packages (from python-resize-image) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.1->python-resize-image) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.1->python-resize-image) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.1->python-resize-image) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.1->python-resize-image) (2024.7.4)\n",
            "Downloading python_resize_image-1.1.20-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: python-resize-image\n",
            "Successfully installed python-resize-image-1.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from resizeimage import resizeimage\n",
        "import imgaug.augmenters as iaa\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive, files\n",
        "import imageio.v2 as imageio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import random\n",
        "import gdown\n",
        "import json\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "uGFtV8B6JhQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prima importiamo le librerie, poi montiamo Google Drive per poter accedere facilmente agli altri file."
      ],
      "metadata": {
        "id": "Mw2Sl_OKyOvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cZtmro2LwaEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4cc8e1-9ddd-4de2-cb76-fa6f7fe60b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Path della cartella del progetto su Google Drive:\n",
        "\n",
        "#@markdown <font color=\"#ed7d31\"><b>Necessario per poter accedere agli altri file</b>!</font>\n",
        "#@markdown <br>Se la cartella del progetto si trova nella root di Drive, scrivere solo il suo nome:\n",
        "DRIVE_PATH = \"MAD Project\" #@param {type:\"string\"}\n",
        "\n",
        "DRIVE_PATH = '/content/drive/MyDrive/' + DRIVE_PATH\n",
        "\n",
        "WEIGHTS_PATH = DRIVE_PATH + '/Weights/'"
      ],
      "metadata": {
        "id": "jd845X6OxKI5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(DRIVE_PATH)                       # ci permetterà di importare le funzioni presenti in altri file\n",
        "from shared_utilities import download_dataset, move_files, split_dataset"
      ],
      "metadata": {
        "id": "EoR_qcsIyTbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scarichiamo dal file .json gli ID necessari per il download del dataset e del csv."
      ],
      "metadata": {
        "id": "K9yayqFuzf6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DRIVE_PATH + '/settings.json', 'r') as file:\n",
        "  config = json.load(file)\n",
        "\n",
        "DATASET_ID = config['DATASET_ID']"
      ],
      "metadata": {
        "id": "PS1wSoh0xDgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Impostazioni del Notebook\n",
        "\n",
        "#@markdown Seme per le funzioni randomiche del notebook:\n",
        "SEED = 2407 #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "np.set_printoptions(suppress=True) # NumPy non utilizzerà la notazione scientifica per piccoli numeri, rendendo l'output più leggibile."
      ],
      "metadata": {
        "id": "3-s-zJBCdcGs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNUJz9e7ZTXf"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "# **Download del dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Impostazioni download\n",
        "\n",
        "#@markdown Nome del zip dataset post download:\n",
        "DATASET_NAME = 'AMSL_dataset.zip' #@param {type:\"string\"}\n",
        "\n",
        "download_dataset(DATASET_ID, DATASET_NAME, msg=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2O1RB0Bd9kKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDrwYsY4ax3v"
      },
      "source": [
        "Dopo aver scaricato il dataset lo manipoliamo in modo da unzipparlo, creare le directory per gli split e infine eliminare i file txt e la cartella sample_data creata automaticamente da Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# evita il fastidioso output a video\n",
        "\n",
        "! unzip \"{DATASET_NAME}\"                                  # unzippa il file zip\n",
        "! rm /content/AMSL/*.txt                                  # elimina i file txt\n",
        "! rm -r /content/sample_data                              # elimina la cartella di default di Colab\n",
        "! mv /content/AMSL/neutral/* /content/AMSL/smiling        # sposta i file della cartella neutral in smiling\n",
        "! mv /content/AMSL/smiling /content/AMSL/bona_fide        # rinomina smiling in bona_fide\n",
        "! rmdir AMSL/neutral                                      # rimuove la cartella neutral (ormai vuota)"
      ],
      "metadata": {
        "id": "z7EkXKMfNTPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3\"></a>\n",
        "# **Resize delle immagini**\n"
      ],
      "metadata": {
        "id": "g2AXM-YIcNba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dimensioni per il resize delle immagini:\n",
        "\n",
        "#@markdown Larghezza dell'immagine:\n",
        "IMAGE_WIDTH = 224 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown Altezza dell'immagine:\n",
        "IMAGE_HEIGHT = 224 #@param {type: \"integer\"}\n",
        "\n",
        "dict_people = {} # salverà il numero di immagini per persona\n",
        "\n",
        "# -- -- #  -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "def resize_images(image_folder, output_folder, target_size):\n",
        "  '''\n",
        "  Funzione per fare la resize delle immagini.\n",
        "\n",
        "  Parametri:\n",
        "  - image_folder: cartella con le immagini da ridimensionare.\n",
        "  - output_folder: cartella dove salvare le immagini ridimensionate.\n",
        "  - target_size: tupla (width, height).\n",
        "  '''\n",
        "\n",
        "  if not os.path.exists(output_folder):                                           # crea la directory per le immagini ridimensionate se non esiste\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "  for image_name in os.listdir(image_folder):                                     # itera attraverso tutte le directory (classi) nell'input folder\n",
        "    class_input_folder = os.path.join(image_folder, image_name)                   # path della cartella della classe specifica in input\n",
        "    class_output_folder = os.path.join(output_folder, image_name)                 # path della cartella della classe specifica nell'output folder\n",
        "\n",
        "    if not os.path.exists(class_output_folder):                                   # crea la directory della classe per le immagini ridimensionate se non esiste\n",
        "      os.makedirs(class_output_folder)\n",
        "\n",
        "    for image_name in os.listdir(class_input_folder):                             # itera attraverso ogni immagine nella cartella della classe\n",
        "      image_path = os.path.join(class_input_folder, image_name)                   # path completo dell'immagine\n",
        "      if os.path.isfile(image_path):                                              # verifica se è un file\n",
        "        with open(image_path, 'r+b') as f:                                        # apre l'immagine\n",
        "          with Image.open(f) as image:\n",
        "            cover = resizeimage.resize_cover(image, target_size)                  # ridimensiona l'immagine alla dimensione target\n",
        "            output_image_path = os.path.join(class_output_folder, image_name)     # path completo per salvare l'immagine ridimensionata\n",
        "            #print(f\"Saving resized image to: {output_image_path}\")               # debug: stampa il path dove sarà salvata l'immagine ridimensionata\n",
        "            cover.save(output_image_path, image.format)                           # salva l'immagine ridimensionata nel path specificato\n",
        "\n",
        "# -- -- #  -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "resize_images('/content/AMSL', '/content/Resized', target_size = (IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "metadata": {
        "id": "3f7HTi2GL4ZA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4\"></a>\n",
        "# **Bilanciamento**\n"
      ],
      "metadata": {
        "id": "bO-rCha5dosP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costruiamo il modello che si occuperà di fare la data augmentation delle immagini."
      ],
      "metadata": {
        "id": "XbE5Z02XfnAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imageGenerator = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),                # flip orizzontale con probabilità del 50%\n",
        "    iaa.Multiply((0.8, 1.2)),       # modificare la luminosità\n",
        "    iaa.Affine(scale=(1, 1.2))      # zoom in avanti fino al 20%\n",
        "])"
      ],
      "metadata": {
        "id": "N6alJGkjOZR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parametri per il bilanciamento\n",
        "\n",
        "#@markdown Numero di immagini da generare per ogni immagine bona_fide:\n",
        "multiplier = 6 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Numero massimo di immagini da morph:\n",
        "max_morph_samples = 1326 #@param {type:\"integer\"}\n",
        "\n",
        "# -- -- # -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "def dataAugmentation(imgPath, multiplier=6):\n",
        "  '''\n",
        "  Funzione che prende in input il percorso di un'immagine e restituisce le immagini generate a partire da lei.\n",
        "\n",
        "  Parametri:\n",
        "  - imgPath: percorso dell'immagine da trasformare.\n",
        "  - multiplier: numero di immagini generate per ogni immagine originale.\n",
        "\n",
        "  Restituisce:\n",
        "  - augmented_images: lista di immagini generate.\n",
        "  '''\n",
        "\n",
        "  image = imageio.imread(imgPath)                                                     # legge l'immagine\n",
        "  image_array = np.array(image)                                                       # converte l'immagine in un array numpy\n",
        "\n",
        "  augmented_images = imageGenerator(images=[image_array for _ in range(multiplier)])  # genera immagini tramite l'imageGenerator\n",
        "\n",
        "  return augmented_images\n",
        "\n",
        "# -- -- # -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "def saveToFile(imgs, image_name, folder):\n",
        "  '''\n",
        "  Funzione per salvare le immagini in un file.\n",
        "\n",
        "  Parametri:\n",
        "  - imgs: lista di immagini da salvare.\n",
        "  - image_name: nome dell'immagine.\n",
        "  - folder: cartella dove salvare le immagini.\n",
        "  '''\n",
        "\n",
        "  global dict_people                                                                  # dizionario globale\n",
        "\n",
        "  image_name = image_name[:3]                                                         # prende i primi 3 caratteri dell'immagine (ID)\n",
        "\n",
        "  if image_name not in dict_people:                                                   # se non è presente nel dizionario\n",
        "    dict_people[image_name] = 1                                                       # inizializza a 1\n",
        "  else:\n",
        "    dict_people[image_name] += 1                                                      # altrimenti incrementa di 1\n",
        "\n",
        "  for img in imgs:                                                                    # per ogni immagine\n",
        "    imageio.imwrite(f'{folder}/{image_name}_{dict_people[image_name]}.jpg', img)      # salva l'immagine nel file\n",
        "    dict_people[image_name] += 1                                                      # incrementa il contatore\n",
        "\n",
        "# -- -- # -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "def BalanceImages(image_folder, output_folder, multiplier, max_morph_samples):\n",
        "  '''\n",
        "  Funzione per bilanciare le immagini in una cartella.\n",
        "\n",
        "  Parametri:\n",
        "  - image_folder: cartella con le immagini da bilanciare.\n",
        "  - output_folder: cartella dove salvare le immagini bilanciate.\n",
        "  - multiplier: numero di immagini generate per ogni immagine originale.\n",
        "  - max_morph_samples: numero massimo di immagini da morph.\n",
        "  '''\n",
        "\n",
        "  if not os.path.exists(output_folder):                                           # crea la directory di output se non esiste\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "  for class_name in os.listdir(image_folder):                                     # itera attraverso tutte le directory (classi) nell'input folder\n",
        "    class_input_folder = os.path.join(image_folder, class_name)                   # percorso della cartella della classe specifica in input\n",
        "    class_output_folder = os.path.join(output_folder, class_name)                 # percorso della cartella della classe specifica nell'output folder\n",
        "\n",
        "    if not os.path.exists(class_output_folder):                                   # crea la directory della classe per le immagini ridimensionate se non esiste\n",
        "      os.makedirs(class_output_folder)\n",
        "\n",
        "    if class_name == 'bona_fide':                                                 # se è la classe bona_fide\n",
        "      for image_name in os.listdir(class_input_folder):                           # itera attraverso ogni immagine nella cartella della classe\n",
        "        image_path = os.path.join(class_input_folder, image_name)                 # percorso completo dell'immagine\n",
        "        augmented_imgs = dataAugmentation(image_path, multiplier=multiplier)      # genera le nuove immagini\n",
        "        saveToFile(augmented_imgs, image_name, class_output_folder)                           # salva le immagini generate nel file\n",
        "    else:\n",
        "      imgs_list = os.listdir(class_input_folder)                                  # lista di tutte le immagini nella cartella della classe\n",
        "      random.shuffle(imgs_list)                                                   # mescola la lista di immagini\n",
        "      for image_name in imgs_list[:max_morph_samples]:\n",
        "        image_path = os.path.join(class_input_folder, image_name)                 # percorso completo dell'immagine\n",
        "        new_image_path = os.path.join(class_output_folder, image_name)            # percorso completo dell'immagine\n",
        "        ! mv \"{image_path}\" \"{new_image_path}\"\n",
        "\n",
        "# -- -- # -- -- # -- -- # -- -- # -- -- # -- -- # -- -- #\n",
        "\n",
        "BalanceImages('/content/Resized', '/content/Balanced', multiplier=6, max_morph_samples=1326)"
      ],
      "metadata": {
        "id": "bXM2jtX9OfMM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numero di immagini bona_fide:\\t%d\" % len(os.listdir('/content/Balanced/bona_fide')))\n",
        "print(\"Numero di immagini morphed:\\t%d\" % len(os.listdir('/content/Balanced/morphed')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEfMr9GFWhGy",
        "outputId": "c88f5c06-042a-4245-abe0-9592b4d75827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di immagini bona_fide:\t1224\n",
            "Numero di immagini morphed:\t1326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5\"></a>\n",
        "# **Salvataggio**"
      ],
      "metadata": {
        "id": "cR6jfBdtsK8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creazione del zip\n",
        "\n",
        "#@markdown Nome del zip da scaricare:<br>\n",
        "#@markdown <font color=\"#ed7d31\"><b>Non inlcudere l'estensione (.zip), caratteri speciali o spazi!</b></font>\n",
        "ZIP_NAME = 'Dataset_Bilanciato_con_ID' #@param {type:\"string\"}\n",
        "\n",
        "!mv /content/AMSL /content/AMSL_temp       # cambiamo nome alla cartella AMSL\n",
        "!mv /content/Balanced /content/AMSL        # rinominiamo la cartella con le immagini pre-processate in AMSL\n",
        "!zip -r /content/{ZIP_NAME}.zip AMSL       # zippiamo (è importante che la root del zip sia una cartella AMSL)\n",
        "!mv /content/AMSL /content/Balanced        # rinominiamo la cartella con le immagini pre-processate al nome originale\n",
        "!mv /content/AMSL_temp /content/AMSL       # rinominiamo la cartella originale in AMSL"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QVUL4yyPu9a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(f'/content/{ZIP_NAME}.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_izlvQ9wyeiS",
        "outputId": "34b571e2-171c-49c2-eec0-9f684e0c1f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_19949fad-c5fb-4d9c-995c-dfe072c73792\", \"Dataset_Bilanciato_con_ID.zip\", 16950787)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}